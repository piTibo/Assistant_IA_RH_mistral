# Assistant_IA_RH_mistral
Assistant IA RH local â€” basÃ© sur le Code du travail 2025 ğŸ‡«ğŸ‡·

Ce projet est un assistant IA local, conÃ§u pour rÃ©pondre Ã  des questions liÃ©es au Code du travail franÃ§ais, sans dÃ©pendance Ã  des services externes (fonctionne entiÃ¨rement en local).  
Il s'appuie sur un moteur de recherche sÃ©mantique avec une base vectorielle Chroma, un modÃ¨le LLaMA (Mistral 7B) en .gguf exÃ©cutÃ© via llama.cpp, et une interface utilisateur simple grÃ¢ce Ã  Gradio.

FonctionnalitÃ©s principales :
- Indexation automatique du Code du travail 2025 (PDF) en vecteurs.
- Recherche intelligente de passages pertinents Ã  l'aide de langchain et Chroma.
- GÃ©nÃ©ration de rÃ©ponses en langage naturel via un modÃ¨le local Mistral.
- Interface web minimaliste pour poser des questions.

## ğŸ“ Fichiers volumineux non inclus

Certaines ressources trop volumineuses ne sont **pas versionnÃ©es** dans le dÃ©pÃ´t. Voici comment les reconstituer :

### ğŸ”¹ Base de donnÃ©es Chroma

Le fichier `chroma_code_travail/chroma.sqlite3` est gÃ©nÃ©rÃ© automatiquement. Pour le reconstituer, il suffit de lancer :

```bash
python index_articles.py
```
### ğŸ”¹ ModÃ¨le de langage LLaMA (Mistral)

Le fichier model/mistral-7b-instruct-v0.1.Q4_K_M.gguf peut Ãªtre tÃ©lÃ©chargÃ© depuis Hugging Face :

â¡ï¸ TÃ©lÃ©chargement sur HuggingFace

ModÃ¨le recommandÃ© : mistral-7b-instruct-v0.1.Q4_K_M.gguf

TÃ©lÃ©chargez-le et placez-le dans le dossier model/.


## Liste des dÃ©pendances
```bash
pip install langchain langchain-community langchain-huggingface llama-cpp-python gradio PyMuPDF
```
